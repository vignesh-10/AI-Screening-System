{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0107e5a6",
   "metadata": {},
   "source": [
    "# AI-Based Candidate Screening System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383ae21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import openai\n",
    "\n",
    "# Set up OpenAI API (Make sure to set your API key here)\n",
    "openai.api_key = 'your-api-key'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40278cb4",
   "metadata": {},
   "source": [
    "### Expanded Dataset of Candidates and Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68748e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Expanded mock interview data (responses for 5 questions)\n",
    "candidates = {\n",
    "    'Candidate A': [\n",
    "        \"Supervised learning uses labeled data, while unsupervised learning uses unlabeled data. Examples include classification for supervised and clustering for unsupervised learning.\",\n",
    "        \"To handle imbalanced data, I would use SMOTE, oversampling, and metrics like precision, recall, and F1-score.\",\n",
    "        \"I built a recommendation system using collaborative filtering and matrix factorization to solve data sparsity issues.\",\n",
    "        \"Overfitting can be reduced using techniques like cross-validation, early stopping, regularization, and dropout in neural networks.\",\n",
    "        \"In the AI landscape, reinforcement learning stands out for its ability to learn through trial and error using feedback, commonly seen in game playing and robotics.\"\n",
    "    ],\n",
    "    'Candidate B': [\n",
    "        \"Supervised learning is when data is labeled, and unsupervised is when it’s not.\",\n",
    "        \"I would balance the dataset by using different sampling methods and focusing on precision.\",\n",
    "        \"I built a chatbot using NLP, but I had some challenges with accuracy.\",\n",
    "        \"Overfitting can be managed by reducing model complexity and tuning hyperparameters.\",\n",
    "        \"Reinforcement learning learns from feedback and is useful for specific tasks like games.\"\n",
    "    ],\n",
    "    'Candidate C': [\n",
    "        \"Supervised learning has labels, unsupervised doesn't.\",\n",
    "        \"I’d change the dataset or use a different model to fix imbalance issues.\",\n",
    "        \"I worked on some AI-related projects, but I don't remember the details.\",\n",
    "        \"Overfitting can be handled by tweaking some parameters.\",\n",
    "        \"Reinforcement learning is important, but I haven't worked with it much.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Expanded predefined expert answers for comparison (gold standard)\n",
    "gold_standard = {\n",
    "    'Question 1': \"Supervised learning uses labeled data to train models and predict outcomes. Unsupervised learning finds hidden patterns in unlabeled data, such as clustering or dimensionality reduction.\",\n",
    "    'Question 2': \"To handle imbalanced data, you can use oversampling, undersampling, SMOTE, or cost-sensitive algorithms. It's important to use evaluation metrics like precision, recall, and F1-score to assess model performance.\",\n",
    "    'Question 3': \"In my recent project, I built a recommendation system using collaborative filtering. The challenge was sparse data, which I addressed using matrix factorization and regularization techniques.\",\n",
    "    'Question 4': \"To avoid overfitting, I used regularization techniques like L2 regularization, early stopping, and cross-validation. In deep learning, dropout is a common technique.\",\n",
    "    'Question 5': \"Reinforcement learning is a type of machine learning where agents learn through trial and error using rewards. It's applied in game AI and robotics for decision-making in dynamic environments.\"\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc39d7",
   "metadata": {},
   "source": [
    "### Function to Evaluate Candidates using GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3414dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to evaluate responses using OpenAI GPT model\n",
    "def gpt_evaluate(candidate_response, question, gold_standard):\n",
    "    prompt = f'''\n",
    "    You are an AI interview evaluator. The candidate's answer is below, followed by the correct expert answer. Rate the candidate's answer on a scale of 0 to 10 based on accuracy, depth of understanding, and clarity.\n",
    "\n",
    "    Question: {question}\n",
    "    \n",
    "    Candidate's answer: {candidate_response}\n",
    "\n",
    "    Expert answer: {gold_standard}\n",
    "\n",
    "    Rate the candidate's answer (0 to 10) and provide a brief explanation:\n",
    "    '''\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "      engine=\"gpt-4\",  # You can use 'gpt-3.5-turbo' or another model if available\n",
    "      prompt=prompt,\n",
    "      max_tokens=150,\n",
    "      temperature=0\n",
    "    )\n",
    "    \n",
    "    # Parse the GPT response for the score\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Evaluate each candidate's response using GPT\n",
    "gpt_scores = {}\n",
    "for candidate, responses in candidates.items():\n",
    "    gpt_scores[candidate] = []\n",
    "    for i, response in enumerate(responses):\n",
    "        question = f\"Question {i+1}\"\n",
    "        expert_answer = gold_standard[question]\n",
    "        score = gpt_evaluate(response, question, expert_answer)\n",
    "        gpt_scores[candidate].append(score)\n",
    "\n",
    "# Display GPT scores for each candidate\n",
    "for candidate, scores in gpt_scores.items():\n",
    "    print(f\"{candidate}'s scores (as evaluated by GPT): {scores}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addca2e6",
   "metadata": {},
   "source": [
    "### Ranking Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregating total score for each candidate\n",
    "total_gpt_scores = {candidate: np.mean([float(score.split()[0]) for score in scores]) for candidate, scores in gpt_scores.items()}\n",
    "\n",
    "# Ranking candidates based on total scores\n",
    "ranked_candidates = sorted(total_gpt_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Display ranked candidates\n",
    "print(\"\\nRanked Candidates (Total Score out of 10):\")\n",
    "for rank, (candidate, score) in enumerate(ranked_candidates, start=1):\n",
    "    print(f\"Rank {rank}: {candidate} with score {score:.2f}/10\")\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
